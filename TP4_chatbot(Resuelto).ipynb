{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bustagar/PROCESAMIENTO-DE-HABLA/blob/main/TP4_chatbot(Resuelto).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TP4 Chatbot\n",
        "\n",
        "## Nombre: Juan Sebastian Bustamante Garcia"
      ],
      "metadata": {
        "id": "BDydrx9x1PF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hghx5BwKdm-A",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install spacy --quiet\n",
        "!python -m spacy download es_core_news_sm --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"es_core_news_sm\")\n",
        "import es_core_news_sm\n",
        "nlp = es_core_news_sm.load()\n",
        "doc = nlp(\"Esto es una frase.\")\n",
        "print([(w.text, w.pos_) for w in doc])"
      ],
      "metadata": {
        "id": "D9SRh-eDdpWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qr3pyit4kWQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chatbots basados en recuperación\n",
        "\n",
        "En inglés information retrieval chatbots"
      ],
      "metadata": {
        "id": "UnrG-1ylkncZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Motor de búsqueda"
      ],
      "metadata": {
        "id": "s3bs1FmWkfrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Búsqueda por palabras clave: Extrae palabras clave de la pregunta del usuario y busca coincidencias en las preguntas almacenadas.\n",
        "\n",
        "* Similitud del coseno: Si has representado las preguntas como vectores (por ejemplo, usando TF-IDF o word embeddings), puedes usar la similitud del coseno para medir la distancia entre las preguntas.\n",
        "\n",
        "* Word embeddings: Utiliza modelos de word embeddings como Word2Vec o BERT para obtener representaciones semánticas de las preguntas y las consultas del usuario."
      ],
      "metadata": {
        "id": "enbz9kXGkWlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Búsqueda por palabras claves"
      ],
      "metadata": {
        "id": "UQoVRp4gjxUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tu_diccionario = {\n",
        "   \"hola\": \"¡Hola! ¿En qué puedo ayudarte?\",\n",
        "   \"adiós\": \"Hasta luego. ¡Que tengas un buen día!\",\n",
        "   \"información\": \"¿Qué tipo de información estás buscando?\",\n",
        "   # Agrega más entradas de diccionario según tus necesidades\n",
        "}\n"
      ],
      "metadata": {
        "id": "3BljEMEOhpTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def responder_pregunta(pregunta):\n",
        "    pregunta_procesada = nlp(pregunta.lower())  # Procesa la pregunta y convierte a minúsculas\n",
        "    respuesta = \"Lo siento, no entiendo tu pregunta.\"\n",
        "\n",
        "    # Busca una coincidencia en el diccionario\n",
        "    for palabra in pregunta_procesada:\n",
        "        # regresa la primer coincidencia que encuentra\n",
        "        if palabra.text in tu_diccionario:\n",
        "            respuesta = tu_diccionario[palabra.text]\n",
        "            break\n",
        "\n",
        "    return respuesta\n"
      ],
      "metadata": {
        "id": "Z4q_k1_3hvyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    entrada_usuario = input(\"Tú: \")\n",
        "    if entrada_usuario.lower() == \"salir\":\n",
        "        print(\"Chatbot: Hasta luego.\")\n",
        "        break\n",
        "    respuesta = responder_pregunta(entrada_usuario)\n",
        "    print(\"Chatbot:\", respuesta)\n"
      ],
      "metadata": {
        "id": "9gMPKi-ghwcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6S88twrY5sOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Búsqueda por similitud"
      ],
      "metadata": {
        "id": "nI2FsyUOj3je"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para los chatbots basados ​​en recuperación, es común utilizar bolsas de palabras (bag of words) o tf-idf para calcular la similitud de intenciones."
      ],
      "metadata": {
        "id": "AoZIaX0Kj7xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Datos de ejemplo\n",
        "preguntas = [\"¿Qué es el aprendizaje automático?\",\n",
        "             \"¿Cómo funciona la regresión lineal?\"]\n",
        "respuestas = [\"El aprendizaje automático es una rama de la inteligencia artificial...\",\n",
        "              \"La regresión lineal es un método de modelado...\"]\n",
        "\n",
        "# Vectorización con TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(preguntas)\n",
        "\n",
        "# Función para encontrar la mejor coincidencia\n",
        "def responder_pregunta(consulta_usuario):\n",
        "    consulta_vec = vectorizer.transform([consulta_usuario])\n",
        "    similitudes = cosine_similarity(consulta_vec, tfidf_matrix).flatten()\n",
        "    print(similitudes)\n",
        "    indice_mejor_coincidencia = similitudes.argmax()\n",
        "    print(indice_mejor_coincidencia)\n",
        "    return respuestas[indice_mejor_coincidencia]\n"
      ],
      "metadata": {
        "id": "CReIz0ISj75s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ejemplo de consulta\n",
        "consulta = \"¿Qué es la regresión lineal?\"\n",
        "print(responder_pregunta(consulta))\n"
      ],
      "metadata": {
        "id": "foqaZ1FN583i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Búsqueda por similitud en embeddings"
      ],
      "metadata": {
        "id": "20KCxfCymOHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puedes vectorizar el texto usando embeddings, como vimos la clase pasada.\n"
      ],
      "metadata": {
        "id": "7g6jgLSLnilX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividades\n",
        "\n",
        "### 1) Elaborar un dataset de preguntas y respuestas para crear un Chatbot para un aplicación particular. ( 3 puntos )\n",
        "\n",
        "1.1 Debe definir la aplicación (atención al cliente bancario, atención a estudiantes universitarios, etc).\n",
        "1.2 El listado de preguntas y respuestas debe tener como mínimo 20 elementos pregunta - respuesta.\n",
        "\n",
        "###  2) Crear el chatbot utilizando TFIDF y similitud del coseno. (1 punto)\n",
        "\n",
        "### 3) Crear otro chatbot utilizando embeddings. Indique cuál embedding (1 punto) pre-entrenado eligió.\n",
        "\n",
        "### 4) Muestra ambos chatbots funcionando (1 punto)\n",
        "\n",
        "Adjuntar la lista de preguntas utilizadas para probar el funcionamiento.\n",
        "\n",
        "### 5) Añade tus conclusiones de todo lo realizado (2 punto)\n",
        "\n",
        "### 6) BONUS: usa lo realizado en 1 y 3 para crear un chatbot RAG. (2 puntos)\n",
        "\n",
        "* Utiliza un modelo LLM pre-entrenado.\n",
        "\n",
        "* Este punto no es obligatorio de realizar para quienes quieran regularizar / recuperar y luego rendirán en mesa.\n",
        "* Para quienes tienen condiciones para promocionar (han realizado y entregado los TPs a tiempo) la resolución de este ejercicio será tenida en cuenta para sumar a la promoción.\n",
        "\n",
        "### 7) No olvides:\n",
        "\n",
        "* Explicar tus decisiones y configuraciones. Añadir tus conclusiones.\n",
        "* Anunciar en el foro cuál será tu aplicación y postear tu entrega y tus avances.\n",
        "* Debes subir tu notebook a un repo GitHub público de tu propiedad compartido + enlace colab.\n",
        "* Documentar todo el proceso.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1sGxF1VglJVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Elección de aplicación (Chatbot Jurídico)"
      ],
      "metadata": {
        "id": "o_6AVESuyxsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga del dataset"
      ],
      "metadata": {
        "id": "gcJawUbYy_ZV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}